{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importing Necessary Packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import datetime\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # advanced vizs\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting Logging"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import logging\n",
    "import logging.handlers\n",
    "import os\n",
    " \n",
    "handler = logging.handlers.WatchedFileHandler(\n",
    "    os.environ.get(\"LOGFILE\", \"../logs/prediction.log\"))\n",
    "formatter = logging.Formatter(logging.BASIC_FORMAT)\n",
    "handler.setFormatter(formatter)\n",
    "root = logging.getLogger()\n",
    "root.setLevel(os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "root.addHandler(handler)\n",
    "logging.info(\"Testing Loggings\") \n",
    "try:\n",
    "    exit(main())\n",
    "except Exception:\n",
    "    logging.exception(\"Exception in main()\")\n",
    "    exit(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Dataframe Class, and object"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Class to load the data\n",
    "class FetchData():\n",
    "    def __init__(self):\n",
    "        self.dfdict = {}\n",
    "        self.dfdict['train'] = self.get_train_data()\n",
    "        self.dfdict['test'] = self.get_test_data()\n",
    "        self.dfdict['sample'] = self.get_sample_data()\n",
    "        self.dfdict['store'] = self.get_store_data()\n",
    "        \n",
    "    def get_train_data(self,name='train'):\n",
    "        filename = f'../data/{name}.csv'\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            logging.info(f\"{name} Dataset read successfully\")\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\" Exception occured in reading dataset, {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_test_data(self,name='test'):\n",
    "        filename = f'../data/{name}.csv'        \n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            logging.info(f\"{name} Dataset read successfully\")\n",
    "            return df   \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\" Exception occured in reading dataset, {e}\")\n",
    "            return None\n",
    "        \n",
    "    def get_store_data(self,name='store'):\n",
    "        filename = f'../data/{name}.csv'        \n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            logging.info(f\"{name} Dataset read successfully\") \n",
    "            return df  \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\" Exception occured in reading dataset, {e}\")\n",
    "            return None \n",
    "    \n",
    "    def get_sample_data(self,name='sample_submission'):\n",
    "        filename = f'../data/{name}.csv'        \n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            logging.info(f\"{name} Dataset read successfully\")  \n",
    "            return df  \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\" Exception occured in reading dataset, {e}\")\n",
    "            return None \n",
    "    \n",
    "    def show_sample_data(self,dataset='train', sample=5):\n",
    "        try:\n",
    "            df = dataset.head(sample)\n",
    "            return df  \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\" Exception occured in getting sample data of a dataset, {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_null_values(self,dataset='train'):\n",
    "        try:\n",
    "            df = dataset.isnull().sum()\n",
    "            logging.info(\"Getting Null values, Execution successfuly\")\n",
    "            return df  \n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\" Exception in getting Null values, {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_start_end_date(self, dataset_name='train', date_column='Date'):\n",
    "        try:\n",
    "            start_date = dataset_name[date_column].min()\n",
    "            end_date = dataset_name[date_column].max()\n",
    "            logging.info(\"Getting start and End date successfully\")\n",
    "            return start_date, end_date\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Exception in getting start and end date, {e}\")\n",
    "\n",
    "            return None, None\n",
    "\n",
    "    def join_dataset(self, dataset='train', dataset1='store'):\n",
    "        if dataset.Store.nunique() == dataset1.Store.nunique():\n",
    "            try:\n",
    "                df_combined = dataset.merge(dataset1, how='left', left_on=dataset.Store, right_on=dataset1.Store)\n",
    "                df_combined.drop(['key_0', 'Store_y'], axis=1, inplace=True)\n",
    "                df_combined = df_combined.rename(columns={'Store_x':'Store'})\n",
    "                logging.info(f\" Joining {dataset} and {dataset1} datasets successfully\")\n",
    "\n",
    "                return df_combined.shape, df_combined\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.debug(f\"Exception in Joining {dataset} and {dataset1} datasets, {e}\")\n",
    "                return None, None\n",
    "\n",
    "        else:\n",
    "            logging.error(\"The values in the dataset are not compartible\")\n",
    "            print(\"The values in the dataset are not compartible\")\n",
    "\n",
    "    def add_day_month_year_to_dataset(self, dataset, column_list = ['day','month','year']):\n",
    "        try:\n",
    "            dataset.Date = pd.to_datetime(dataset.Date)\n",
    "            for column in column_list:\n",
    "                dataset[column] = dataset.Date.dt.column\n",
    "                logging.info(f\"Adding {column} column to dataset successfully\")\n",
    "                return dataset\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Exception occured in Adding columns in dataset, Exception:{e}\")\n",
    "             \n",
    "            return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#  Creating FetchData Object\n",
    "data = FetchData()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = data.get_train_data(\"train\")\n",
    "store_data = data.get_train_data(\"store\")\n",
    "test_data = data.get_train_data(\"test\")\n",
    "sample_submission_data = data.get_train_data(\"sample_submission\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fc5b00bee59e553d508db9922ccda4ed2426092ffdded382ff87e02c7f5799df"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}